---
title: Neurosymbolic Tag-Based Annotation for Interpretable Avatar Creation
openreview: ROcvabXGkL
abstract: Avatar creation from human images presents challenges for direct neural
  approaches, which suffer from inconsistent predictions and poor interpretability
  due to the large parameter space with hundreds of ambiguous options. We propose
  a neurosymbolic tag-based annotation method that combines neural perceptual learning
  with symbolic semantic reasoning. Instead of directly predicting avatar parameters,
  our approach uses a neural network to predict semantic tags (hair length, curliness,
  direction) as an intermediate symbolic representation, then applies symbolic search
  algorithms to match optimal avatar assets. This neurosymbolic design produces higher
  annotator agreements (96.7% vs 31.0% for direct annotation), enables more consistent
  model predictions, and provides interpretable avatar selection with ranked alternatives.
  The tag-based system generalizes easily across rendering systems, requiring only
  new asset annotation while reusing human image tags. Experimental results demonstrate
  superior convergence, consistency, and visual quality compared to direct prediction
  methods, showing how neurosymbolic approaches can improve trustworthiness and interpretability
  in creative AI applications.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu25a
month: 0
tex_title: Neurosymbolic Tag-Based Annotation for Interpretable Avatar Creation
firstpage: 589
lastpage: 624
page: 589-624
order: 589
cycles: false
bibtex_author: Liu, Minghao and Cheng, Zeyu and Sang, Shen and Liu, Jing and Davis,
  James
author:
- given: Minghao
  family: Liu
- given: Zeyu
  family: Cheng
- given: Shen
  family: Sang
- given: Jing
  family: Liu
- given: James
  family: Davis
date: 2025-10-07
address:
container-title: Proceedings of The 19th International Conference on Neurosymbolic
  Learning and Reasoning
volume: '284'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v284/main/assets/liu25a/liu25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
