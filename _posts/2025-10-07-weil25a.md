---
title: Adapting Graph-Based Analysis for Knowledge Extraction from Transformer Models
section: Poster
openreview: xrSYOIdrPz
abstract: Transformer models, despite their exceptional capabilities in Natural Language
  Processing (NLP) and Vision tasks, like deep neural network models, often function
  as "black boxes" as their internal processes remain largely opaque due to their
  complex architectures. This work extends graph-based knowledge extraction techniques,
  previously applied to CNNs, to the domain of Transformer models. The inner mechanics
  of Transformer models are explored by constructing a co-activation graph from their
  encoder layers. The nodes of the graph represent the hidden unit within each encoder
  layer, while the edges represent the statistical correlations between these hidden
  units. The magnitude of co-activation, which is the correlation between activations
  of two hidden units, determines the strength of their connection within the graph.
  Our research is focused on encoder-only Transformer classifiers. We conducted experiments
  involving a custom-built Transformer and a pre-trained BERT model for an NLP task.
  We used graph analysis to detect semantically related class clusters and their impact
  on misclassification patterns. We demonstrate a positive correlation between class
  similarity and the frequency of classification errors.  Our findings suggest that
  co-activation graphs reveal structured, interpretable representations in Transformers,
  consistent with prior CNN findings on knowledge extraction.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: weil25a
month: 0
tex_title: Adapting Graph-Based Analysis for Knowledge Extraction from Transformer
  Models
firstpage: 1
lastpage: 14
page: 1-14
order: 1
cycles: false
bibtex_author: Weil, Alexandre Monnier and Horta, Vitor A. C. and Qadeer, Hamza and
  Mileo, Alessandra
author:
- given: Alexandre Monnier
  family: Weil
- given: Vitor A. C.
  family: Horta
- given: Hamza
  family: Qadeer
- given: Alessandra
  family: Mileo
date: 2025-10-07
address:
container-title: Proceedings of The 19th International Conference on Neurosymbolic
  Learning and Reasoning
volume: '284'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v284/main/assets/weil25a/weil25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
