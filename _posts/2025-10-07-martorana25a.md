---
title: 'Bridging Bots: from Perception to Action via Multimodal-LMs and Knowledge
  Graphs'
section: Poster
openreview: XZ5UsD6YT6
abstract: Personal service robots are increasingly deployed to support daily living
  in domestic environments, particularly for  elderly and individuals requiring assistance.
  These robots must perceive complex and dynamic surroundings, understand tasks, and
  execute context-appropriate actions. However, current systems typically rely on
  proprietary, hard-coded solutions tied to specific hardware and software, resulting
  in siloed implementations that are difficult to adapt and scale across platforms.
  Ontologies and Knowledge Graphs (KGs) offer a solution to enable interoperability
  across systems, through structured and standardized representations of knowledge
  and reasoning. However, symbolic systems such as KGs and ontologies struggle with
  raw and noisy sensory input. In contrast, multimodal language models are well suited
  for interpreting input such as images and natural language, but often lack transparency,
  consistency, and knowledge grounding. In this work, we propose a neurosymbolic framework
  that combines the perceptual strengths of multimodal language models with the structured
  representations provided by KGs and ontologies, with the aim of supporting interoperability
  in robotic applications. Our approach generates ontology-compliant KGs that can
  inform robot behavior in a platform-independent manner. We evaluated this framework
  by integrating robot perception data, ontologies, and five multimodal models (three
  LLaMA-based and two GPT-based models), each using different modes of neural-symbolic
  interaction. We assess the consistency and effectiveness of the generated KGs across
  multiple runs and configurations, and perform statistical analyzes to evaluate performance.
  Results show that GPT-o1 and LLaMA 4 Maverick consistently outperform other models.
  However, our findings also indicate that newer models do not guarantee better results,
  highlighting the critical role of the integration strategy in generating ontology-compliant
  KGs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: martorana25a
month: 0
tex_title: 'Bridging Bots: from Perception to Action via Multimodal-LMs and Knowledge
  Graphs'
firstpage: 625
lastpage: 646
page: 625-646
order: 625
cycles: false
bibtex_author: Martorana, Margherita and Urgese, Francesca and Adamik, Mark and Tiddi,
  Ilaria
author:
- given: Margherita
  family: Martorana
- given: Francesca
  family: Urgese
- given: Mark
  family: Adamik
- given: Ilaria
  family: Tiddi
date: 2025-10-07
address:
container-title: Proceedings of The 19th International Conference on Neurosymbolic
  Learning and Reasoning
volume: '284'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v284/main/assets/martorana25a/martorana25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
