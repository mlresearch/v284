---
title: Description Logic Concept Learning using Large Language Models
section: Poster
software: https://github.com/AdritaBarua/DL-learner-using-LLMs/tree/main
openreview: ebVC7S5VMF
abstract: 'Recent advances in Large Language Models (LLMs) have drawn interest in
  their capacity for logical reasoning, an area traditionally dominated by symbolic
  systems that rely on complete, manually curated knowledge bases represented in formal
  languages. This paper introduces a framework that leverages pretrained LLMs to generate
  Description Logic (DL) class expressions from instance-level examples and background
  knowledge, translated to natural language. The baseline is Concept Induction, a
  symbolic learning approach that is mostly based on formal logical reasoning over
  a DL theory. Drawing inspiration from the DL-Learner architecture, our approach
  replaces traditional symbolic methods with LLM-based models to generate DL class
  expressions from instance-level data.  We evaluate our approach using three benchmark
  ontologies across two LLMs: gpt-4o and o3-mini. We use a symbolic reasoner, Pellet,
  to verify the LLM-generated results and incorporate the reasoner’s feedback into
  our pipeline to ensure logical consistency, thereby generating a hybrid neurosymbolic
  system. By introducing controlled variations to the background knowledge, we assess
  the models’ reliance on commonsense versus formal reasoning. Results show that o3-mini
  achieves near-perfect accuracy across settings, albeit with longer runtime. These
  findings demonstrate that LLMs have the potential to serve as scalable and flexible
  DL learners when coupled in a hybrid neurosymbolic setting, offering a promising
  alternative to symbolic approaches—particularly in contexts where high-quality ontologies
  are incomplete or unavailable.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: barua25a
month: 0
tex_title: Description Logic Concept Learning using Large Language Models
firstpage: 160
lastpage: 178
page: 160-178
order: 160
cycles: false
bibtex_author: Barua, Adrita and Hitzler, Pascal
author:
- given: Adrita
  family: Barua
- given: Pascal
  family: Hitzler
date: 2025-10-07
address:
container-title: Proceedings of The 19th International Conference on Neurosymbolic
  Learning and Reasoning
volume: '284'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v284/main/assets/barua25a/barua25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
