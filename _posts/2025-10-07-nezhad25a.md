---
title: Enhancing Large Language Models with Neurosymbolic Reasoning for Multilingual
  Tasks
openreview: T8XSti6sRj
abstract: Large language models (LLMs) often struggle to perform multi-target reasoning
  in long-context scenarios where relevant information is scattered across extensive
  documents. To address this challenge, we introduce {NeuroSymbolic Augmented Reasoning
  (NSAR)}, which combines the benefits of neural and symbolic reasoning during inference.
  NSAR explicitly extracts symbolic facts from text and generates executable Python
  code to handle complex reasoning steps. Through extensive experiments across seven
  languages and diverse context lengths, we demonstrate that NSAR significantly outperforms
  both a vanilla RAG baseline and advanced prompting strategies in accurately identifying
  and synthesizing multiple pieces of information. Our results highlight the effectiveness
  of combining explicit symbolic operations with neural inference for robust, interpretable,
  and scalable reasoning in multilingual settings.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nezhad25a
month: 0
tex_title: Enhancing Large Language Models with Neurosymbolic Reasoning for Multilingual
  Tasks
firstpage: 1059
lastpage: 1076
page: 1059-1076
order: 1059
cycles: false
bibtex_author: Nezhad, Sina Bagheri and Agrawal, Ameeta
author:
- given: Sina Bagheri
  family: Nezhad
- given: Ameeta
  family: Agrawal
date: 2025-10-07
address:
container-title: Proceedings of The 19th International Conference on Neurosymbolic
  Learning and Reasoning
volume: '284'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v284/main/assets/nezhad25a/nezhad25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
