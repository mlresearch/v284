---
title: Practical Lessons on Vector-Symbolic Architectures in Deep Learning-Inspired
  Environments
openreview: 5ZmvZkqyoy
abstract: Neural networks have shown unprecedented capabilities, rivaling human performance
  in many tasks. However, current neural architectures are not capable of symbolic
  manipulation, which is thought to be a hallmark of human intelligence. Vector-symbolic
  architectures (VSAs) promise to bring this ability through simple vector manipulation,
  highly amenable to current and emerging hardware and software stacks built for their
  neural counterparts. Integrating the two models into the paradigm of neuro-vector-symbolic
  architectures may achieve even more human-like performance. However, despite ongoing
  efforts, there are no clear guidelines on the deployment of VSA in deep learning-based
  training situations. In this work, we aim to begin providing such guidelines by
  offering four practical lessons we have observed through the analysis of many VSA
  models and implementations. We provide thorough benchmarks and results that corroborate
  such lessons. First, we observe that Multiply-add-permute (MAP) and Hadamard linear
  binding (HLB) are up to 3-4$\times$ faster than holographic reduced representations
  (HRR), even when the latter is equipped with optimized FFT-based convolutions. Second,
  we propose further speed improvements by replacing similarity search with a linear
  readout, with no effect on retrieval. Third, we analyze the retrieval performance
  of MAP, HRR and HLB in a noise-free and noisy scenario to simulate processing by
  a neural network, and show that they are equivalent. Finally, we implement a hierarchical
  multi-level composition scheme, with notable benefits to the flexibility of integration
  of VSAs inside existing neural architectures. Overall, we show that these four lessons
  lead to faster and more effective deployment of VSA.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: carzaniga25a
month: 0
tex_title: Practical Lessons on Vector-Symbolic Architectures in Deep Learning-Inspired
  Environments
firstpage: 218
lastpage: 236
page: 218-236
order: 218
cycles: false
bibtex_author: Carzaniga, Francesco S. and Hersche, Michael and Schindler, Kaspar
  and Rahimi, Abbas
author:
- given: Francesco S.
  family: Carzaniga
- given: Michael
  family: Hersche
- given: Kaspar
  family: Schindler
- given: Abbas
  family: Rahimi
date: 2025-10-07
address:
container-title: Proceedings of The 19th International Conference on Neurosymbolic
  Learning and Reasoning
volume: '284'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v284/main/assets/carzaniga25a/carzaniga25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
