---
title: Disentangling Neural Disjunctive Normal Form Models
software: https://github.com/kittykg/disentangling-ndnf-classification
openreview: 66YzQK1eLW
abstract: Neural Disjunctive Normal Form (DNF) based models are powerful and interpretable
  approaches to neuro-symbolic learning and have shown promising results in classification
  and reinforcement learning settings without prior knowledge of the tasks. However,
  their performance is degraded by the thresholding of the post-training symbolic
  translation process. We show here that part of the performance degradation during
  translation is due to its failure to disentangle the learned knowledge represented
  in the form of the networks’ weights. We address this issue by proposing a new disentanglement
  method; by splitting nodes that encode nested rules into smaller independent nodes,
  we are able to better preserve the models’ performance. Through experiments on binary,
  multiclass, and multilabel classification tasks (including those requiring predicate
  invention), we demonstrate that our disentanglement method provides compact and
  interpretable logical representations for the neural DNF-based models, with performance
  closer to that of their pre-translation counterparts. Our code is available at https://github.com/kittykg/disentangling-ndnf-classification.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: baugh25a
month: 0
tex_title: Disentangling Neural Disjunctive Normal Form Models
firstpage: 463
lastpage: 493
page: 463-493
order: 463
cycles: false
bibtex_author: Baugh, Kexin Gu and Perreault, Vincent and Baugh, Matthew and Dickens,
  Luke and Inoue, Katsumi and Russo, Alessandra
author:
- given: Kexin Gu
  family: Baugh
- given: Vincent
  family: Perreault
- given: Matthew
  family: Baugh
- given: Luke
  family: Dickens
- given: Katsumi
  family: Inoue
- given: Alessandra
  family: Russo
date: 2025-10-07
address:
container-title: Proceedings of The 19th International Conference on Neurosymbolic
  Learning and Reasoning
volume: '284'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v284/main/assets/baugh25a/baugh25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
